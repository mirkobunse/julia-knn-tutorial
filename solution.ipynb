{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CAUTION:** You are watching the solution. If you want to solve this exercise yourself, open `assignment.ipynb` instead\n",
    "\n",
    "---\n",
    "\n",
    "## 1) Loading the Data\n",
    "\n",
    "You do not need to make any changes in this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "using MLDataUtils, Random\n",
    "Random.seed!(123) # set the random number seed\n",
    "\n",
    "# load the IRIS data set and split it into a training and a test set\n",
    "X, y = MLDataUtils.load_iris()\n",
    "(X_trn, y_trn), (X_tst, y_tst) = splitobs(shuffleobs((X, y)), at=0.666)\n",
    "\n",
    "# I assume you are more familiar with a (n_samples, n_features) shape than\n",
    "# with the (n_features, n_samples) shape used by MLDataUtils.jl\n",
    "X_trn = transpose(X_trn) # now the shape looks like the one used by sklearn\n",
    "X_tst = transpose(X_tst)\n",
    "\n",
    "; # ending with a semicolon omits printing the output of a cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Computing the Euclidean Distance\n",
    "\n",
    "The euclidean distance between two vectors `a` and `b` is the square root of the sum of their squared component-wise differences: https://en.wikipedia.org/wiki/Euclidean_distance\n",
    "\n",
    "Your task is now to compute the euclidean distance between arbitrary vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "euclidean (generic function with 2 methods)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I started with:   euclidean(a, b) = sqrt(sum((a-b).^2))\n",
    "\n",
    "euclidean(a::AbstractArray{T,1}, b::AbstractArray{T,1}) where T<:Number =\n",
    "  sqrt(sum((a-b).^2)) # square root of the dot product\n",
    "\n",
    "euclidean(a::AbstractArray{T,1}, B::AbstractArray{T,2}) where T<:Number =\n",
    "  map(b -> euclidean(a, b), eachrow(B)) # distance of one point a to each point in B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000028 seconds (9 allocations: 156.578 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40.78569015203682"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can use this cell to test your implementation\n",
    "a_tst = Random.rand(10000) # 100000-element Array{Float64,1}\n",
    "b_tst = Random.rand(10000)\n",
    "@time euclidean(a_tst, b_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000419 seconds (59 allocations: 1.528 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10-element Array{Float64,1}:\n",
       " 41.0881382297078  \n",
       " 41.051803443649206\n",
       " 40.87838569551084 \n",
       " 41.15719200334341 \n",
       " 40.701273788375886\n",
       " 41.196095202334696\n",
       " 40.81874523856506 \n",
       " 40.59544693406834 \n",
       " 40.958666005666316\n",
       " 40.897928276524624"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can you also compute the distance of one point to all other points?\n",
    "a_tst = Random.rand(10000) # 100000-element Array{Float64,1}\n",
    "B_tst = Random.rand(10, 10000) # 10 such vectors, i.e. a 3x10000-element Array{Float64,2}\n",
    "@time euclidean(a_tst, B_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) k-NN Classification\n",
    "\n",
    "A k-NN classifier stores the entire training set. When predicting a new example, it computes the distance of this example to all training examples. The k closest training examples are allowed to vote for a prediction. The label which occurs most often is used as the final prediction.\n",
    "\n",
    "**Note:** I already provide you with the (generic) type `KNN` because Jupyter complains when types are re-defined. This would happen just too often during development. Feel free to make changes, but remember to restart your kernel then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct KNN{T_X<:Number, T_y<:Any}\n",
    "    X::AbstractArray{T_X,2} # training set (features)\n",
    "    y::AbstractArray{T_y,1} # training set (labels)\n",
    "    k::Int64 # k, the number of neighbors to consider\n",
    "end\n",
    "\n",
    "# you can instantiate an object of this type by calling KNN(X, y, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 2 methods)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function predict(knn::KNN{T_X,T_y}, X::AbstractArray{T_X,1}) where {T_X<:Number, T_y<:Any}\n",
    "    votes = knn.y[sortperm(euclidean(X, knn.X))[1:knn.k]]\n",
    "    vote_counts = countmap(votes) # map unique values to counts\n",
    "    return findmax(vote_counts)[2] # findmax returns a (count, vote) pair\n",
    "end\n",
    "\n",
    "predict(knn::KNN{T_X,T_y}, X::AbstractArray{T_X,2}) where {T_X<:Number, T_y<:Any} =\n",
    "  map(x -> predict(knn, x), eachrow(X)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Estimate the Accuracy\n",
    "\n",
    "You can use the test set to make predictions and compare them with true labels. The accuracy is defined as the fraction of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.001508 seconds (21.02 k allocations: 1.517 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_tst = KNN(X_trn, y_trn, 3)\n",
    "@time sum(predict(knn_tst, X_tst) .== y_tst) / length(y_tst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.0",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
